#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""Queue manager - wait for assignments to appear and invoke vmchecker-vm-executor to handle them.

This module depends on pyinotify: http://pyinotify.sourceforge.net/
For each bundle:
  * listen for new files on a directory,
  * decompress the bundle to a temporary directory,
  * pass path of the directory to the executor,
  * waits for the executor to finish.

At startup it checks whether there are any stale jobs and executes them
all as described above.

"""

from __future__ import with_statement

import os
import sys
import time
import shutil
import signal
import tempfile
import optparse
import subprocess
from pyinotify import WatchManager, Notifier, ProcessEvent, EventsCodes
from threading import Thread, Lock
from Queue import Queue

from vmchecker.courselist import CourseList
from vmchecker.config import Config, TesterCourseConfig
from vmchecker.paths  import VmcheckerPaths
from vmchecker import submissions
from vmchecker import vmlogging
from vmchecker import callback
from vmchecker import ziputil


EXIT_SUCCESS = 0
EXIT_FAIL = 1

_logger = vmlogging.create_script_stdout_logger()
vmqueue_lock = Lock()
vmexecutor_timeout = None

def prepare_workers(vmcfg):

    num_workers = vmcfg.num_workers()
    _logger.info('Using %d workers.' % num_workers)
    duplicated_vms = vmcfg.duplicated_vms()

    assignment_queue = Queue()

    # Here we create a set of queues per each duplicated vm.
    # NOTE: For VMs that are not duplicated we will create the queues
    # during execution
    vms_conf = {}
    vms_queues = {}

    for vm in duplicated_vms:
        vm_conf = {}
        vm_queue = Queue()
        vms_conf[vm] = vm_conf
        vms_queues[vm] = vm_queue
        for section in vmcfg.sections():
            if section != vm and section.startswith(vm):
                worker_id = section[len(vm):]
                wk_conf = {}
                vm_conf[worker_id] = wk_conf

                for item in vmcfg.config.items(section):
                    wk_conf[item[0]] = item[1]

                vm_queue.put(worker_id)

    workers = []
    for i in range(num_workers):
        worker = Thread(target = launch_worker, args = (assignment_queue, vms_queues, vms_conf))
        workers.append(worker)
        worker.start()

    return (workers, assignment_queue)


def upload_results_to_sender(bundle_dir):
    """Runs callback script to upload results"""
    try:
        allfiles = os.listdir(bundle_dir)
        vmrfiles = []
        for fname in allfiles:
            if fname.endswith('.vmr'):
                vmrfiles.append(os.path.join(bundle_dir, fname))
        sb_config = os.path.join(bundle_dir, 'submission-config')
        callback.run_callback(sb_config, vmrfiles, callback.STATUS_DONE)
    except:
        # XXX: don't know whether to allow exceptions to kill
        # queue-manager or not. Silent exceptions will most certainly
        # run unnoticed, QM crashes will surely be noticed by students
        _logger.exception("--Queue-Manager: error while sending back results")


class _InotifyHandler(ProcessEvent):
    """Dummy class needed to start processing events"""

    def __init__(self, vmpaths, assignment_queue):
        self.vmpaths = vmpaths
        self.assignment_queue = assignment_queue

    def process_IN_CLOSE_WRITE(self, event):
        """Called when a write ends (this means a new
        bundle has arrived). Imediatly start the new job.

        """
        _logger.info('Processing job "%s" in queue dir "%s"' % (
                event.name, event.path))
        self.assignment_queue.put((event.path, event.name, self.vmpaths))


def log_vmchecker_stderr(location, string):
    """Writes a message to 'vmchecker-stderr.vmr'"""
    vmchecker_stderr = os.path.join(location, 'vmchecker-stderr.vmr')
    with open(vmchecker_stderr, 'a+') as handler:
        print >> handler, string

def log_vmchecker_grade(location, exit_code):
    """Writes 'ok' or 'error' to 'grade.vmr'.
       If exit_code equals 0 then the result is 'ok', otherwise it is 'error'.
    """
    vmchecker_grade = os.path.join(location, 'grade.vmr')
    with open(vmchecker_grade, 'w') as handler:
        print >> handler, [submissions.STATUS_ERROR, submissions.STATUS_DONE] [ exit_code == 0 ]


def launch_external_downloader(location):
    """Launch a program to download any external files needed for
    testing"""
    try:
        # download additional files into the bundle dir (location)
        subprocess.call(['vmchecker-download-external-files', location])
    except OSError:
        _logger.exception('Cannot invoke vmchecker-download-external-files.')


def launch_executor(location):
    """Launch the vmchecker-vm-executor process and kill it if it runs
    for too long"""

    deadline = time.time() + vmexecutor_timeout
    _logger.info('Begin homework evaluation. Location %s', location)

    # launch vmchecker-vm-executor
    try:
        popen = subprocess.Popen(['vmchecker-vm-executor', location])
    except OSError:
        _logger.exception('Cannot invoke vmchecker-vm-executor.')
        log_vmchecker_grade(location, EXIT_FAIL)
        log_vmchecker_stderr(location, 'Cannot run vmchecker-vm-executor.')
        log_vmchecker_stderr(location, 'Please contact the administrators.')
        # if we cannot open the process, there is nothing more that can be done
        return

    # wait for vmchecker-vm-executor to finish runing or kill it.
    try:
        counter = 0
        while time.time() < deadline:
            counter += 1
            exit_code = popen.poll()
            if exit_code != None:
                # the process has terminated. Write to log and return.
                log_vmchecker_stderr(location, 'vmexecutor exitcode %d (%s)' % (
                        exit_code, ['error', 'success'] [ exit_code == 0 ]))
                log_vmchecker_grade(location, exit_code)
                return
            # if process has not finished => continue to poll every 5s
            _logger.debug('-- QM sleep(5): total=%d max=%d', counter * 5,
                          vmexecutor_timeout)
            time.sleep(5)
        else:
            log_vmchecker_stderr(location, "VMExecutor successfuly " + \
                      "started, but it's taking too long. Check your " + \
                      "sources, makefiles, etc and resubmit. If the " + \
                      "problem persists please contact administrators.")
            log_vmchecker_grade(location, EXIT_FAIL)
    except (IOError, OSError):
        _logger.exception('Exception while waiting for vmexecutor to end')

    try:
        # can't do "popen.kill()" here because it only
        # available from python 2.6
        # First send a SIGINT, and then a SIGTERM. This
        # gives the executor time to fire its 'finally' blocks
        # and, thus, not leak any running VM processes or
        # host commands.
        os.kill(popen.pid, signal.SIGINT)
        time.sleep(5)
        os.kill(popen.pid, signal.SIGTERM)
    except OSError:
        _logger.exception('Exception in kill(PID=%d)', popen.pid)

def launch_worker(assignment_queue, vms_queues, vms_conf):
    while True:
        (path, name, vmpaths) = assignment_queue.get()
        _logger.info("-- QM: Start processing job.")
        process_job(path, name, vmpaths, vms_queues, vms_conf)
        assignment_queue.task_done()

def reserve_vm_and_patch_cfg(sb_cfg_file, vms_queues, vms_conf):
    sb_cfg = Config(sb_cfg_file)
    assg_vm = sb_cfg.get('Assignment', 'Machine')

    # First check if this VM is duplicated, and if not,
    # create a Queue for it, if not already existent

    if not vms_queues.has_key(assg_vm):
        vmqueue_lock.acquire()
        if not vms_queues.has_key(assg_vm):
            vms_queues[assg_vm] = Queue()
            vms_queues[assg_vm].put('default')
        vmqueue_lock.release()

    # Reserve a worker or wait for one to become available
    worker = vms_queues[assg_vm].get()

    if vms_conf.has_key(assg_vm):
        # Patch the submission-config to use the duplicated VM
        vm_conf = vms_conf[assg_vm]
        wk_conf = vm_conf[worker]
        for key in wk_conf:
            if sb_cfg.config.has_option('Machine', key):
                _logger.info("Overwriting %s in section %s with %s" % (key, assg_vm, wk_conf[key]))
                sb_cfg.config.set('Machine', key, wk_conf[key])

        with open(sb_cfg_file, "w") as handler:
            sb_cfg.config.write(handler)

    return (assg_vm, worker)

def release_vm(assg_vm, worker, vms_queues):
    vms_queues[assg_vm].task_done()
    vms_queues[assg_vm].put(worker)

def process_job(path, name, vmpaths, vms_queues, vms_conf):
    """Unzip a bundle archive and call the commander."""
    location = tempfile.mkdtemp(prefix='vmchecker-',
                                dir=vmpaths.dir_tester_unzip_tmp())
    bundle_archive = os.path.join(path, name)
    try:
        ziputil.unzip_safely(bundle_archive, location)
        _logger.info('-- QM: unzipped bundle (config/tests/scripts/etc)')
        launch_external_downloader(location)
        _logger.info('-- QM: finished downloading external dependencies')

        sb_cfg_file = os.path.join(location, 'submission-config')
        (assg_vm, worker) = reserve_vm_and_patch_cfg(sb_cfg_file, vms_queues, vms_conf)

        callback.run_callback(sb_cfg_file, None, callback.STATUS_PROCESSING)
        launch_executor(location)

        release_vm(assg_vm, worker, vms_queues)

        _logger.info('-- QM: finished testing - sending results')
        upload_results_to_sender(location)
    except:
        _logger.exception('Failed to process "%s".' % location)

    _logger.info('Cleaning "%s"' % location)
    shutil.rmtree(location)

    _logger.info('Removing job from the queue')
    os.unlink(bundle_archive)


def process_stale_jobs(dir_queue, vmpaths, assignment_queue):
    """The queue_manager may die leaving jobs unchecked.
    This function runs the commander for each job found
    in the queue directory at startup.

    """
    stale_jobs = os.listdir(dir_queue)
    if len(stale_jobs) == 0:
        _logger.info('No stale jobs in queue dir "%s"' % dir_queue)
    for stale_job in stale_jobs:
        _logger.info('Processing stale job "%s" in queue dir "%s"' % (
                stale_job, dir_queue))
        assignment_queue.put((dir_queue, stale_job, vmpaths))


def _callback(watch_manager):
    """Called after each event is processed in the Notifier. We just
    use it to write to the logger that we finished processing.

    """
    _logger.info('Waiting for the next job to arrive')


def start_queue(vmpaths, assignment_queue):
    """ Process any stale jobs and register with inotify to wait
    for new jobs to arrive.

    """
    dir_queue = vmpaths.dir_queue()

    # register for inotify envents before processing stale jobs
    watch_manager = WatchManager()
    watch_manager.add_watch(dir_queue, EventsCodes.ALL_FLAGS['IN_CLOSE_WRITE'])
    notifier = Notifier(watch_manager, _InotifyHandler(vmpaths, assignment_queue))
    process_stale_jobs(dir_queue, vmpaths, assignment_queue)

    # set callback to receive notifications (includes queued jobs after
    # setting up inotify but before we finished processing stale jobs)
    notifier.loop(callback=_callback)


def check_tester_setup_correctly(vmpats):
    """ Sanity check:
        * all needed paths are present
    """
    # check needed paths setup correctly
    for path in vmpats.tester_paths():
        if not os.path.isdir(path):
            _logger.error('"%s" missing. Run `vmchecker-init-course tester`' % path)
            exit(1)


def redirect_std_files(stdin_fname=None, stdout_fname=None, stderr_fname=None):
    """Redirect standard files for the files that are not null"""
    if stdin_fname != None:
        stdin = file(stdin_fname, 'r')
        os.dup2(stdin.fileno(), sys.stdin.fileno())

    if stdout_fname != None:
        sys.stdout.flush()
        stdout = file(stdout_fname, 'a+')
        os.dup2(stdout.fileno(), sys.stdout.fileno())

    if stderr_fname != None:
        sys.stderr.flush()
        stderr = file(stderr_fname, 'a+', 0)
        os.dup2(stderr.fileno(), sys.stderr.fileno())


def main():
    """Entry point for the queue manager"""
    cmdline = optparse.OptionParser()
    cmdline.add_option('-0', '--stdin',  dest='stdin',  default=None,
                       help='Redirect stdin to FILE.',  metavar='FILE')
    cmdline.add_option('-1', '--stdout', dest='stdout', default=None,
                       help='Redirect stdout to FILE.', metavar='FILE')
    cmdline.add_option('-2', '--stderr', dest='stderr', default=None,
                       help='Redirect stderr to FILE.', metavar='FILE')
    cmdline.add_option('-c', '--course_id', dest='course_id',
                       help='The course id for which to start the queue manager.')
    (options, _) = cmdline.parse_args()

    course_id = options.course_id
    if course_id == None:
        print "course_id parameter required"
        exit(1)

    redirect_std_files(options.stdin, options.stdout, options.stderr)

    vmcfg = TesterCourseConfig(CourseList().course_config(course_id))
    vmpaths = VmcheckerPaths(vmcfg.root_path_queue_manager())
    global vmexecutor_timeout
    vmexecutor_timeout = vmcfg.vmexecutor_timeout()

    os.chdir(vmcfg.root_path_queue_manager())
    # fail early if something is not setup corectly, and not at a
    # distant point when we'll need these things.
    check_tester_setup_correctly(vmpaths)

    # start worker pool
    (workers, assignment_queue) = prepare_workers(vmcfg)
    start_queue(vmpaths, assignment_queue)

if __name__ == '__main__':
    main()
